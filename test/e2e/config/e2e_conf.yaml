---
# E2E test scenario using local dev images and manifests built from the source tree for following providers:
# - cluster-api
# - bootstrap kubeadm
# - control-plane kubeadm
# - metal3

images:
  # Use local dev images built source tree;
  - name: quay.io/metal3-io/cluster-api-provider-metal3:latest
    loadBehavior: mustLoad
  - name: quay.io/metal3-io/baremetal-operator:latest
    loadBehavior: mustLoad
  - name: quay.io/metal3-io/ip-address-manager:latest
    loadBehavior: mustLoad

providers:
- name: cluster-api
  type: CoreProvider
  versions:
  - name: v1.1.2
    # Use manifest from source files
    value: "https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.1.2/core-components.yaml"
    type: "url"
    contract: v1beta1
    files:
      - sourcePath: "../data/shared/v1beta1/metadata.yaml"
    replacements:
      - old: "--leader-elect"
        new: "--leader-elect=false"
- name: kubeadm
  type: BootstrapProvider
  versions:
  - name: v1.1.2
    # Use manifest from source files
    value: "https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.1.2/bootstrap-components.yaml"
    type: "url"
    contract: v1beta1
    files:
      - sourcePath: "../data/shared/v1beta1/metadata.yaml"
    replacements:
      - old: "--leader-elect"
        new: "--leader-elect=false"
- name: kubeadm
  type: ControlPlaneProvider
  versions:
  - name: v1.1.2
    # Use manifest from source files
    value: "https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.1.2/control-plane-components.yaml"
    type: "url"
    contract: v1beta1
    files:
      - sourcePath: "../data/shared/v1beta1/metadata.yaml"
    replacements:
      - old: "--leader-elect"
        new: "--leader-elect=false"
- name: metal3
  type: InfrastructureProvider
  versions:
  - name: v1.1.0
    value: "file://${HOME}/.cluster-api/overrides/infrastructure-metal3/v1.1.0/infrastructure-components.yaml"
    type: "url"
    contract: v1beta1
    files:
    - sourcePath: "../../../metadata.yaml"
      targetName: "metadata.yaml"
    - sourcePath: "../_out/cluster-template-ubuntu.yaml"
      targetName: "cluster-template-ubuntu.yaml"
    - sourcePath: "../_out/cluster-template-centos.yaml"
      targetName: "cluster-template-centos.yaml"

variables:
  KUBERNETES_VERSION: "${KUBERNETES_VERSION}"
  UPGRADED_K8S_VERSION: "${UPGRADED_K8S_VERSION}"
  CNI: "/tmp/calico.yaml"
  APIVersion: "infrastructure.cluster.x-k8s.io/${CAPM3_VERSION}"
  NAMEPREFIX: "${NAMEPREFIX:-baremetal-operator}"
  IRONIC_NAMESPACE: "${IRONIC_NAMESPACE:-baremetal-operator-system}"
  CONTAINER_REGISTRY: "${CONTAINER_REGISTRY:-quay.io}"
  IRONIC_IMAGE_TAG: "${IRONIC_IMAGE_TAG:-main}"
  MARIADB_IMAGE_TAG: "${MARIADB_IMAGE_TAG:-main}"
  UPGRADED_BMO_IMAGE_TAG: "${UPGRADED_BMO_IMAGE_TAG:-main}"
  CAPIRELEASE: "${CAPIRELEASE}"
  CAPM3RELEASE: "${CAPM3RELEASE}"
  CONFIG_FILE_PATH: "${HOME}/.cluster-api/overrides/clusterctl.yaml"
  # Default vars for the template, those values could be overridden by the env-vars.
  SERVICE_CIDR: "10.96.0.0/12"
intervals:
  default/wait-controllers: ["3m", "10s"]
  default/wait-cluster: ["20m", "30s"] # The second time to check the availibility of the cluster should happen late, so kcp object has time to be created
  default/wait-control-plane: ["30m", "10s"]
  default/wait-worker-nodes: ["30m", "10s"]
  default/wait-delete-cluster: ["20m", "10s"]
  default/wait-machine-upgrade: ["50m", "10s"]
  default/wait-machine-remediation: ["30m", "10s"]
  default/wait-vm-state: ["20m", "100ms"]
  default/monitor-vm-state: ["1m", "500ms"]
  default/monitor-provisioning: ["5m", "500ms"]
  default/wait-deployment: ["10m", "10s"]
  default/wait-job: ["10m", "10s"]
  default/wait-service: ["10m", "10s"]
  default/wait-object-provisioned: ["10m", "10s"]
  default/wait-cp-available: ["50m", "30s"]
  default/wait-bmh-deprovisioning: ["50m", "10s"]
  default/wait-bmh-available: ["50m", "20s"]
  default/wait-bmh-inspecting: ["10m", "2s"]
  default/wait-machine-deleting: ["7m", "2s"]
  default/wait-bmh-deprovisioning-available: ["7m", "500ms"]
  default/wait-bmh-available-provisioning: ["5m", "2s"]
  default/wait-machine-running: ["50m", "20s"]
  default/wait-bmh-provisioned: ["50m", "20s"]
  default/wait-pod-restart: ["6m", "10s"]
